{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f40da009",
   "metadata": {},
   "source": [
    "Design an object detection model using deep neural networks for simple objects.\n",
    "a.\t Select appropriate dataset and perform data pre-processing \n",
    "b.\t Define architecture in terms of layers \n",
    "c.\t Evaluate Model performance Label the object with appropriate text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7505ce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f79610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Variant folder C:\\Users\\Shlok Sonkusare\\tensorflow_datasets\\oxford_iiit_pet\\4.0.0 has no dataset_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\Shlok Sonkusare\\tensorflow_datasets\\oxford_iiit_pet\\4.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shlok Sonkusare\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:02<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:02<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:13<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:14<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:18<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:24<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:24<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:29<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:29<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:30<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:32<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:33<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:35<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:37<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:37<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:40<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:41<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:42<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:45<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:45<?, ? url/s]\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "# Correct way to load Oxford-IIIT Pet dataset\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset, info = tfds.load(\"oxford_iiit_pet\", with_info=True, as_supervised=False)\n",
    "\n",
    "train_data = dataset['train']\n",
    "test_data = dataset['test']\n",
    "\n",
    "# Print dataset info\n",
    "print(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4153acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "def preprocess(sample):\n",
    "    image = tf.image.resize(sample['image'], (IMG_SIZE, IMG_SIZE)) / 255.0\n",
    "    bbox = sample['objects']['bbox'][0]  # Use only the first object per image for simplicity\n",
    "    label = sample['objects']['label'][0]\n",
    "\n",
    "    # Convert relative bbox to absolute\n",
    "    ymin, xmin, ymax, xmax = bbox\n",
    "    bbox = tf.stack([ymin * IMG_SIZE, xmin * IMG_SIZE, ymax * IMG_SIZE, xmax * IMG_SIZE])\n",
    "    \n",
    "    return image, {'bbox': bbox, 'label': label}\n",
    "\n",
    "train_data = train_data.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_data = test_data.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dce266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "def build_model():\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "    # Output 1: Bounding Box\n",
    "    bbox_output = layers.Dense(4, name='bbox')(x)\n",
    "\n",
    "    # Output 2: Label classification\n",
    "    label_output = layers.Dense(info.features['objects']['label'].num_classes, activation='softmax', name='label')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=[bbox_output, label_output])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23b66ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'bbox': 'mse',\n",
    "        'label': 'sparse_categorical_crossentropy'\n",
    "    },\n",
    "    metrics={\n",
    "        'bbox': 'mae',\n",
    "        'label': 'accuracy'\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d0589",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=test_data,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca1f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f564f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = info.features['objects']['label'].names\n",
    "\n",
    "def draw_bbox(image, bbox, label):\n",
    "    ymin, xmin, ymax, xmax = bbox\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "\n",
    "    # Draw rectangle\n",
    "    rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, color='red')\n",
    "    ax.add_patch(rect)\n",
    "    plt.text(xmin, ymin - 10, class_names[label], color='red', fontsize=12)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Predict on one batch\n",
    "for images, targets in test_data.take(1):\n",
    "    pred_bbox, pred_labels = model.predict(images)\n",
    "\n",
    "    for i in range(3):\n",
    "        img = images[i].numpy()\n",
    "        bbox = pred_bbox[i]\n",
    "        label = np.argmax(pred_labels[i])\n",
    "        draw_bbox(img, bbox, label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
